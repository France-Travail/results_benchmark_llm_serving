{
    "model": "llama-3.3-70b-instruct-awq",
    "step_live_metrics": 0.01,
    "max_queries": 1000,
    "request_rate": 0,
    "backend": "happy_vllm",
    "suite_id": "2025-02-12, 08:49:17",
    "model_name": "llama-3.3-70b-instruct-awq",
    "happy_vllm_version": "1.1.15",
    "vllm_version": "0.7.1",
    "host": "0.0.0.0",
    "port": 8501,
    "app_name": "happy_vllm",
    "api_endpoint_prefix": "/api_vllm/rs",
    "explicit_errors": false,
    "allow_credentials": false,
    "allowed_origins": [
        "*"
    ],
    "allowed_methods": [
        "*"
    ],
    "allowed_headers": [
        "*"
    ],
    "uvicorn_log_level": "info",
    "ssl_keyfile": null,
    "ssl_certfile": null,
    "ssl_ca_certs": null,
    "ssl_cert_reqs": 0,
    "root_path": null,
    "lora_modules": null,
    "chat_template": null,
    "chat_template_content_format": "auto",
    "response_role": "assistant",
    "with_launch_arguments": true,
    "return_tokens_as_token_ids": false,
    "max_log_len": null,
    "prompt_adapters": null,
    "disable_frontend_multiprocessing": true,
    "enable_request_id_headers": false,
    "enable_auto_tool_choice": false,
    "enable_reasoning": false,
    "reasoning_parser": null,
    "tool_call_parser": null,
    "tool_parser_plugin": "",
    "disable_fastapi_docs": false,
    "enable_prompt_tokens_details": false,
    "task": "auto",
    "tokenizer": null,
    "skip_tokenizer_init": false,
    "revision": null,
    "code_revision": null,
    "tokenizer_revision": null,
    "tokenizer_mode": "auto",
    "trust_remote_code": false,
    "allowed_local_media_path": null,
    "download_dir": null,
    "load_format": "auto",
    "config_format": "auto",
    "dtype": "auto",
    "kv_cache_dtype": "auto",
    "max_model_len": 100000,
    "guided_decoding_backend": "xgrammar",
    "logits_processor_pattern": null,
    "distributed_executor_backend": null,
    "pipeline_parallel_size": 1,
    "tensor_parallel_size": 2,
    "max_parallel_loading_workers": null,
    "ray_workers_use_nsight": false,
    "block_size": null,
    "enable_prefix_caching": null,
    "disable_sliding_window": false,
    "use_v2_block_manager": true,
    "num_lookahead_slots": 0,
    "seed": 0,
    "swap_space": 4.0,
    "cpu_offload_gb": 0.0,
    "gpu_memory_utilization": 0.9,
    "num_gpu_blocks_override": null,
    "max_num_batched_tokens": null,
    "max_num_seqs": null,
    "max_logprobs": 20,
    "disable_log_stats": false,
    "quantization": "awq",
    "rope_scaling": null,
    "rope_theta": null,
    "hf_overrides": null,
    "enforce_eager": false,
    "max_seq_len_to_capture": 8192,
    "disable_custom_all_reduce": false,
    "tokenizer_pool_size": 0,
    "tokenizer_pool_type": "ray",
    "tokenizer_pool_extra_config": null,
    "limit_mm_per_prompt": null,
    "mm_processor_kwargs": null,
    "disable_mm_preprocessor_cache": false,
    "enable_lora": false,
    "enable_lora_bias": false,
    "max_loras": 1,
    "max_lora_rank": 16,
    "lora_extra_vocab_size": 256,
    "lora_dtype": "auto",
    "long_lora_scaling_factors": null,
    "max_cpu_loras": null,
    "fully_sharded_loras": false,
    "enable_prompt_adapter": false,
    "max_prompt_adapters": 1,
    "max_prompt_adapter_token": 0,
    "device": "auto",
    "num_scheduler_steps": 1,
    "multi_step_stream_outputs": true,
    "scheduler_delay_factor": 0.0,
    "enable_chunked_prefill": null,
    "speculative_model": null,
    "speculative_model_quantization": null,
    "num_speculative_tokens": null,
    "speculative_disable_mqa_scorer": false,
    "speculative_draft_tensor_parallel_size": null,
    "speculative_max_model_len": null,
    "speculative_disable_by_batch_size": null,
    "ngram_prompt_lookup_max": null,
    "ngram_prompt_lookup_min": null,
    "spec_decoding_acceptance_method": "rejection_sampler",
    "typical_acceptance_sampler_posterior_threshold": null,
    "typical_acceptance_sampler_posterior_alpha": null,
    "disable_logprobs_during_spec_decoding": null,
    "model_loader_extra_config": null,
    "ignore_patterns": [],
    "preemption_mode": null,
    "served_model_name": null,
    "qlora_adapter_name_or_path": null,
    "otlp_traces_endpoint": null,
    "collect_detailed_traces": null,
    "disable_async_output_proc": false,
    "scheduling_policy": "fcfs",
    "override_neuron_config": null,
    "override_pooler_config": null,
    "compilation_config": null,
    "kv_transfer_config": null,
    "worker_cls": "auto",
    "generation_config": null,
    "override_generation_config": null,
    "enable_sleep_mode": false,
    "calculate_kv_scales": false,
    "disable_log_requests": false,
    "engine_use_ray": false,
    "gpu_name": "H100"
}