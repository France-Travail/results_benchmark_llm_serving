INFO:Benchmark suite:2024-11-22, 09:54:19 Beginning the benchmark for the prompt ingestion speed
INFO:Benchmark suite:2024-11-22, 09:54:19 Benchmark for the prompt ingestion speed : instance 0 
INFO:Benchmark for LLMs:2024-11-22, 09:54:19 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 09:54:19 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 09:54:34 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:54:45 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:54:57 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:55:10 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:55:23 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:55:35 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:55:46 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:55:59 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:56:12 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:56:24 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:56:25 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 09:56:26 Derived calculations done
INFO:Benchmark suite:2024-11-22, 09:56:26 Benchmark for the prompt ingestion speed : instance 0 : DONE
INFO:Benchmark suite:2024-11-22, 09:56:26 Benchmark for the prompt ingestion speed : instance 1 
INFO:Benchmark for LLMs:2024-11-22, 09:56:26 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 09:56:26 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 09:56:40 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:56:51 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:57:03 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:57:16 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:57:29 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:57:41 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:57:53 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:58:06 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:58:19 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:58:31 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:58:32 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 09:58:32 Derived calculations done
INFO:Benchmark suite:2024-11-22, 09:58:32 Benchmark for the prompt ingestion speed : instance 1 : DONE
INFO:Benchmark suite:2024-11-22, 09:58:32 Benchmark for the prompt ingestion speed : instance 2 
INFO:Benchmark for LLMs:2024-11-22, 09:58:32 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 09:58:32 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 09:58:47 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:58:59 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:59:11 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:59:23 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:59:36 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 09:59:48 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:00:01 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:00:13 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:00:26 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:00:38 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:00:39 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 10:00:39 Derived calculations done
INFO:Benchmark suite:2024-11-22, 10:00:39 Benchmark for the prompt ingestion speed : instance 2 : DONE
INFO:Benchmark suite:2024-11-22, 10:00:39 Benchmark for the prompt ingestion speed : instance 3 
INFO:Benchmark for LLMs:2024-11-22, 10:00:39 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 10:00:39 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 10:00:53 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:01:05 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:01:18 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:01:30 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:01:43 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:01:55 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:02:08 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:02:20 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:02:33 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:02:45 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:02:47 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 10:02:47 Derived calculations done
INFO:Benchmark suite:2024-11-22, 10:02:47 Benchmark for the prompt ingestion speed : instance 3 : DONE
INFO:Benchmark suite:2024-11-22, 10:02:47 Benchmark for the prompt ingestion speed : DONE
INFO:Benchmark suite:2024-11-22, 10:02:47 Beginning the benchmarks for the KV cache profile
INFO:Benchmark suite:2024-11-22, 10:02:47 Beginning the benchmark for the KV cache profile, input length : 32, output_length : 16
INFO:Benchmark for LLMs:2024-11-22, 10:02:47 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 10:02:47 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 10:02:48 Launching 0 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:02:49 Launching 1 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:02:50 Launching 2 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:02:50 Launching 3 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:02:51 Launching 4 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:02:52 Launching 5 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:02:53 Launching 6 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:02:53 Launching 7 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:02:54 Launching 8 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:02:55 Launching 9 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:02:56 Launching 10 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:02:56 Launching 11 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:02:57 Launching 12 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:02:58 Launching 13 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:02:59 Launching 14 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:02:59 Launching 15 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:00 Launching 16 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:01 Launching 17 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:02 Launching 18 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:02 Launching 19 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:03 Launching 20 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:04 Launching 21 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:05 Launching 22 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:05 Launching 23 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:06 Launching 24 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:07 Launching 25 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:08 Launching 26 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:09 Launching 27 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:09 Launching 28 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:10 Launching 29 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:11 Launching 30 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:12 Launching 31 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:13 Launching 32 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:13 Launching 33 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:14 Launching 34 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:15 Launching 35 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:16 Launching 36 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:17 Launching 37 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:18 Launching 38 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:19 Launching 39 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:20 Launching 40 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:21 Launching 41 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:22 Launching 42 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:23 Launching 43 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:23 Launching 44 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:25 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 10:03:25 Derived calculations done
INFO:Benchmark suite:2024-11-22, 10:03:25 Benchmark for the KV cache profile, input length : 32, output_length : 16 : DONE
INFO:Benchmark suite:2024-11-22, 10:03:25 Beginning the benchmark for the KV cache profile, input length : 32, output_length : 128
INFO:Benchmark for LLMs:2024-11-22, 10:03:25 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 10:03:25 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 10:03:28 Launching 0 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:28 Launching 1 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:30 Launching 2 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:32 Launching 3 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:34 Launching 4 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:36 Launching 5 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:38 Launching 6 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:40 Launching 7 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:42 Launching 8 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:44 Launching 9 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:46 Launching 10 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:48 Launching 11 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:50 Launching 12 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:52 Launching 13 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:54 Launching 14 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:56 Launching 15 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:03:58 Launching 16 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:01 Launching 17 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:03 Launching 18 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:05 Launching 19 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:07 Launching 20 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:09 Launching 21 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:11 Launching 22 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:13 Launching 23 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:15 Launching 24 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:18 Launching 25 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:20 Launching 26 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:22 Launching 27 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:24 Launching 28 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:27 Launching 29 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:29 Launching 30 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:31 Launching 31 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:34 Launching 32 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:36 Launching 33 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:39 Launching 34 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:41 Launching 35 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:43 Launching 36 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:46 Launching 37 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:49 Launching 38 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:51 Launching 39 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:54 Launching 40 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:56 Launching 41 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:04:59 Launching 42 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:05:01 Launching 43 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:05:04 Launching 44 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:05:08 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 10:05:08 Derived calculations done
INFO:Benchmark suite:2024-11-22, 10:05:08 Benchmark for the KV cache profile, input length : 32, output_length : 128 : DONE
INFO:Benchmark suite:2024-11-22, 10:05:08 Beginning the benchmark for the KV cache profile, input length : 32, output_length : 1024
INFO:Benchmark for LLMs:2024-11-22, 10:05:08 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 10:05:08 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 10:05:20 Launching 0 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:05:20 Launching 1 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:05:32 Launching 2 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:05:44 Launching 3 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:05:55 Launching 4 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:06:07 Launching 5 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:06:19 Launching 6 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:06:31 Launching 7 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:06:44 Launching 8 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:06:57 Launching 9 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:07:10 Launching 10 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:07:23 Launching 11 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:07:37 Launching 12 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:07:52 Launching 13 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:08:06 Launching 14 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:08:20 Launching 15 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:08:35 Launching 16 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:08:50 Launching 17 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:09:05 Launching 18 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:09:20 Launching 19 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:09:35 Launching 20 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:09:50 Launching 21 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:10:06 Launching 22 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:10:21 Launching 23 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:10:37 Launching 24 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:10:52 Launching 25 queries in parallel
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-189210' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-189206' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-189208' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-189200' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-189204' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-189202' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
INFO:Benchmark for LLMs:2024-11-22, 10:11:09 Launching 26 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:11:25 Launching 27 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:11:42 Launching 28 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:12:00 Launching 29 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:12:17 Launching 30 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:12:35 Launching 31 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:12:53 Launching 32 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:13:11 Launching 33 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:13:30 Launching 34 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:13:48 Launching 35 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:14:08 Launching 36 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:14:27 Launching 37 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:14:46 Launching 38 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:06 Launching 39 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:24 Max duration 600s has been reached
INFO:Benchmark for LLMs:2024-11-22, 10:15:25 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 10:15:26 Derived calculations done
INFO:Benchmark suite:2024-11-22, 10:15:26 Benchmark for the KV cache profile, input length : 32, output_length : 1024 : DONE
INFO:Benchmark suite:2024-11-22, 10:15:26 Beginning the benchmark for the KV cache profile, input length : 1024, output_length : 16
INFO:Benchmark for LLMs:2024-11-22, 10:15:26 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 10:15:26 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 10:15:28 Launching 0 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:28 Launching 1 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:29 Launching 2 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:30 Launching 3 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:31 Launching 4 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:32 Launching 5 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:33 Launching 6 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:34 Launching 7 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:35 Launching 8 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:36 Launching 9 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:37 Launching 10 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:38 Launching 11 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:40 Launching 12 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:41 Launching 13 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:42 Launching 14 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:44 Launching 15 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:46 Launching 16 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:47 Launching 17 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:49 Launching 18 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:51 Launching 19 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:52 Launching 20 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:54 Launching 21 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:56 Launching 22 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:15:58 Launching 23 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:00 Launching 24 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:02 Launching 25 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:04 Launching 26 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:06 Launching 27 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:08 Launching 28 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:10 Launching 29 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:13 Launching 30 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:15 Launching 31 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:17 Launching 32 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:20 Launching 33 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:22 Launching 34 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:25 Launching 35 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:27 Launching 36 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:30 Launching 37 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:33 Launching 38 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:36 Launching 39 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:38 Launching 40 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:41 Launching 41 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:44 Launching 42 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:47 Launching 43 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:51 Launching 44 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:54 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 10:16:54 Derived calculations done
INFO:Benchmark suite:2024-11-22, 10:16:55 Benchmark for the KV cache profile, input length : 1024, output_length : 16 : DONE
INFO:Benchmark suite:2024-11-22, 10:16:55 Beginning the benchmark for the KV cache profile, input length : 1024, output_length : 128
INFO:Benchmark for LLMs:2024-11-22, 10:16:55 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 10:16:55 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 10:16:57 Launching 0 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:16:58 Launching 1 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:00 Launching 2 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:02 Launching 3 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:04 Launching 4 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:06 Launching 5 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:08 Launching 6 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:11 Launching 7 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:14 Launching 8 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:16 Launching 9 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:19 Launching 10 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:22 Launching 11 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:25 Launching 12 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:28 Launching 13 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:31 Launching 14 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:34 Launching 15 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:37 Launching 16 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:41 Launching 17 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:44 Launching 18 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:48 Launching 19 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:51 Launching 20 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:55 Launching 21 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:17:59 Launching 22 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:18:02 Launching 23 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:18:06 Launching 24 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:18:10 Launching 25 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:18:15 Launching 26 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:18:20 Launching 27 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:18:24 Launching 28 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:18:29 Launching 29 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:18:33 Launching 30 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:18:38 Launching 31 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:18:43 Launching 32 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:18:48 Launching 33 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:18:52 Launching 34 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:18:57 Launching 35 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:19:02 Launching 36 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:19:08 Launching 37 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:19:13 Launching 38 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:19:19 Launching 39 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:19:24 Launching 40 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:19:29 Launching 41 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:19:35 Launching 42 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:19:41 Launching 43 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:19:47 Launching 44 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:19:54 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 10:19:54 Derived calculations done
INFO:Benchmark suite:2024-11-22, 10:19:54 Benchmark for the KV cache profile, input length : 1024, output_length : 128 : DONE
INFO:Benchmark suite:2024-11-22, 10:19:54 Beginning the benchmark for the KV cache profile, input length : 1024, output_length : 1024
INFO:Benchmark for LLMs:2024-11-22, 10:19:54 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 10:19:54 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 10:20:06 Launching 0 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:20:06 Launching 1 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:20:18 Launching 2 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:20:30 Launching 3 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:20:41 Launching 4 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:20:54 Launching 5 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:21:07 Launching 6 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:21:22 Launching 7 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:21:37 Launching 8 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:21:52 Launching 9 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:22:08 Launching 10 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:22:25 Launching 11 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:22:43 Launching 12 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:23:00 Launching 13 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:23:18 Launching 14 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:23:37 Launching 15 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:23:56 Launching 16 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:24:15 Launching 17 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:24:37 Launching 18 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:24:58 Launching 19 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:25:20 Launching 20 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:25:42 Launching 21 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:26:04 Launching 22 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:26:26 Launching 23 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:26:49 Launching 24 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:27:13 Launching 25 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:27:37 Launching 26 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:28:00 Launching 27 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:28:25 Launching 28 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:28:52 Launching 29 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:29:19 Launching 30 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:29:47 Launching 31 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:14 Max duration 600s has been reached
INFO:Benchmark for LLMs:2024-11-22, 10:30:15 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 10:30:15 Derived calculations done
INFO:Benchmark suite:2024-11-22, 10:30:15 Benchmark for the KV cache profile, input length : 1024, output_length : 1024 : DONE
INFO:Benchmark suite:2024-11-22, 10:30:15 Beginning the benchmark for the KV cache profile, input length : 4096, output_length : 16
INFO:Benchmark for LLMs:2024-11-22, 10:30:15 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 10:30:15 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 10:30:17 Launching 0 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:18 Launching 1 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:18 Launching 2 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:20 Launching 3 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:21 Launching 4 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:23 Launching 5 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:24 Launching 6 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:26 Launching 7 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:29 Launching 8 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:31 Launching 9 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:34 Launching 10 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:37 Launching 11 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:40 Launching 12 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:44 Launching 13 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:47 Launching 14 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:51 Launching 15 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:55 Launching 16 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:30:59 Launching 17 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:31:04 Launching 18 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:31:09 Launching 19 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:31:14 Launching 20 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:31:20 Launching 21 queries in parallel
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-406128' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
INFO:Benchmark for LLMs:2024-11-22, 10:31:25 Launching 22 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:31:31 Launching 23 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:31:37 Launching 24 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:31:43 Launching 25 queries in parallel
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-411248' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
INFO:Benchmark for LLMs:2024-11-22, 10:31:49 Launching 26 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:31:56 Launching 27 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:32:03 Launching 28 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:32:10 Launching 29 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:32:17 Launching 30 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:32:25 Launching 31 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:32:33 Launching 32 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:32:41 Launching 33 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:32:49 Launching 34 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:32:58 Launching 35 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:33:07 Launching 36 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:33:16 Launching 37 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:33:25 Launching 38 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:33:35 Launching 39 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:33:45 Launching 40 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:33:55 Launching 41 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:34:05 Launching 42 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:34:15 Launching 43 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:34:26 Launching 44 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:34:37 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 10:34:37 Derived calculations done
INFO:Benchmark suite:2024-11-22, 10:34:38 Benchmark for the KV cache profile, input length : 4096, output_length : 16 : DONE
INFO:Benchmark suite:2024-11-22, 10:34:38 Beginning the benchmark for the KV cache profile, input length : 4096, output_length : 128
INFO:Benchmark for LLMs:2024-11-22, 10:34:38 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 10:34:38 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 10:34:40 Launching 0 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:34:41 Launching 1 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:34:43 Launching 2 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:34:45 Launching 3 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:34:48 Launching 4 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:34:51 Launching 5 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:34:55 Launching 6 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:34:59 Launching 7 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:35:04 Launching 8 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:35:08 Launching 9 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:35:13 Launching 10 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:35:19 Launching 11 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:35:24 Launching 12 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:35:30 Launching 13 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:35:37 Launching 14 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:35:43 Launching 15 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:35:50 Launching 16 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:35:58 Launching 17 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:36:07 Launching 18 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:36:15 Launching 19 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:36:24 Launching 20 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:36:33 Launching 21 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:36:42 Launching 22 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:36:52 Launching 23 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:37:02 Launching 24 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:37:12 Launching 25 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:37:23 Launching 26 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:37:34 Launching 27 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:37:45 Launching 28 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:37:57 Launching 29 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:38:10 Launching 30 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:38:23 Launching 31 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:38:37 Launching 32 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:38:52 Launching 33 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:39:07 Launching 34 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:39:23 Launching 35 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:39:39 Launching 36 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:39:55 Launching 37 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:40:12 Launching 38 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:40:29 Launching 39 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:40:46 Launching 40 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:41:04 Launching 41 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:41:22 Launching 42 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:41:40 Launching 43 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:41:59 Launching 44 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:42:19 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 10:42:19 Derived calculations done
INFO:Benchmark suite:2024-11-22, 10:42:19 Benchmark for the KV cache profile, input length : 4096, output_length : 128 : DONE
INFO:Benchmark suite:2024-11-22, 10:42:19 Beginning the benchmark for the KV cache profile, input length : 4096, output_length : 1024
INFO:Benchmark for LLMs:2024-11-22, 10:42:19 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 10:42:19 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 10:42:31 Launching 0 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:42:31 Launching 1 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:42:43 Launching 2 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:42:57 Launching 3 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:43:11 Launching 4 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:43:28 Launching 5 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:43:46 Launching 6 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:44:06 Launching 7 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:44:28 Launching 8 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:44:51 Launching 9 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:45:15 Launching 10 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:45:42 Launching 11 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:46:09 Launching 12 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:46:38 Launching 13 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:47:08 Launching 14 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:47:40 Launching 15 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:48:13 Launching 16 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:48:49 Launching 17 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:49:28 Launching 18 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:50:08 Launching 19 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:50:50 Launching 20 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:51:32 Launching 21 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:52:16 Launching 22 queries in parallel
INFO:Benchmark for LLMs:2024-11-22, 10:53:00 Max duration 600s has been reached
INFO:Benchmark for LLMs:2024-11-22, 10:53:01 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 10:53:01 Derived calculations done
INFO:Benchmark suite:2024-11-22, 10:53:02 Benchmark for the KV cache profile, input length : 4096, output_length : 1024 : DONE
INFO:Benchmark suite:2024-11-22, 10:53:02 Benchmarks for the KV cache profile : DONE
INFO:Benchmark suite:2024-11-22, 10:53:02 Beginning the benchmarks for the generation speed
INFO:Benchmark suite:2024-11-22, 10:53:02 Beginning the benchmarks for the generation speed, input length : 32, output_length : 16
INFO:Benchmark suite:2024-11-22, 10:53:02 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 1
INFO:Benchmark for LLMs:2024-11-22, 10:53:02 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 10:53:02 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 10:53:22 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:53:41 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:54:01 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:54:20 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:54:40 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:54:59 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:55:18 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:55:37 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:55:57 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:56:17 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:56:18 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 10:56:18 Derived calculations done
INFO:Benchmark suite:2024-11-22, 10:56:18 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 1 : DONE
INFO:Benchmark suite:2024-11-22, 10:56:18 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 2
INFO:Benchmark for LLMs:2024-11-22, 10:56:18 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 10:56:18 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 10:56:31 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:56:43 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:56:55 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:57:07 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:57:19 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:57:31 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:57:43 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:57:55 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:58:07 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:58:19 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:58:20 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 10:58:20 Derived calculations done
INFO:Benchmark suite:2024-11-22, 10:58:20 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 2 : DONE
INFO:Benchmark suite:2024-11-22, 10:58:20 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 3
INFO:Benchmark for LLMs:2024-11-22, 10:58:20 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 10:58:20 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 10:58:29 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:58:37 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:58:45 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:58:54 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:59:02 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:59:10 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:59:18 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:59:26 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:59:34 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:59:42 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:59:43 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 10:59:43 Derived calculations done
INFO:Benchmark suite:2024-11-22, 10:59:43 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 3 : DONE
INFO:Benchmark suite:2024-11-22, 10:59:43 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 4
INFO:Benchmark for LLMs:2024-11-22, 10:59:43 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 10:59:43 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 10:59:51 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 10:59:57 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:00:03 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:00:09 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:00:15 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:00:22 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:00:28 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:00:34 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:00:40 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:00:46 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:00:47 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:00:47 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:00:47 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 4 : DONE
INFO:Benchmark suite:2024-11-22, 11:00:47 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 6
INFO:Benchmark for LLMs:2024-11-22, 11:00:47 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:00:47 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:00:53 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:00:57 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:01:01 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:01:05 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:01:10 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:01:14 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:01:18 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:01:22 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:01:26 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:01:30 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:01:31 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:01:31 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:01:31 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 6 : DONE
INFO:Benchmark suite:2024-11-22, 11:01:31 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 8
INFO:Benchmark for LLMs:2024-11-22, 11:01:31 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:01:31 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:01:36 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:01:39 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:01:42 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:01:45 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:01:48 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:01:51 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:01:55 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:01:58 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:02 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:05 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:06 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:02:06 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:02:06 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 8 : DONE
INFO:Benchmark suite:2024-11-22, 11:02:06 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 10
INFO:Benchmark for LLMs:2024-11-22, 11:02:06 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:02:06 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:02:10 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:13 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:15 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:18 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:21 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:23 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:26 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:29 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:31 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:34 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:35 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:02:35 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:02:35 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 10 : DONE
INFO:Benchmark suite:2024-11-22, 11:02:35 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 14
INFO:Benchmark for LLMs:2024-11-22, 11:02:35 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:02:35 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:02:38 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:40 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:42 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:44 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:46 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:48 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:50 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:52 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:54 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:56 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:02:57 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:02:57 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:02:57 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 14 : DONE
INFO:Benchmark suite:2024-11-22, 11:02:57 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 18
INFO:Benchmark for LLMs:2024-11-22, 11:02:57 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:02:57 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:03:00 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:03 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:04 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:06 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:07 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:09 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:11 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:13 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:14 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:16 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:17 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:03:17 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:03:17 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 18 : DONE
INFO:Benchmark suite:2024-11-22, 11:03:17 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 22
INFO:Benchmark for LLMs:2024-11-22, 11:03:17 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:03:17 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:03:20 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:22 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:23 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:24 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:26 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:27 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:28 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:30 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:32 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:33 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:34 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:03:35 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:03:35 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 22 : DONE
INFO:Benchmark suite:2024-11-22, 11:03:35 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 26
INFO:Benchmark for LLMs:2024-11-22, 11:03:35 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:03:35 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:03:37 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:39 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:40 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:41 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:43 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:44 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:45 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:47 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:48 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:49 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:50 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:03:50 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:03:50 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 26 : DONE
INFO:Benchmark suite:2024-11-22, 11:03:50 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 30
INFO:Benchmark for LLMs:2024-11-22, 11:03:50 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:03:50 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:03:53 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:55 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:56 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:57 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:03:59 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:00 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:01 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:02 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:03 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:05 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:06 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:04:06 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:04:06 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 30 : DONE
INFO:Benchmark suite:2024-11-22, 11:04:06 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 34
INFO:Benchmark for LLMs:2024-11-22, 11:04:06 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:04:06 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:04:08 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:10 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:11 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:13 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:14 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:16 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:17 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:18 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:19 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:20 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:21 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:04:21 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:04:21 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 34 : DONE
INFO:Benchmark suite:2024-11-22, 11:04:21 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 38
INFO:Benchmark for LLMs:2024-11-22, 11:04:21 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:04:21 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:04:25 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:26 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:27 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:28 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:29 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:30 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:31 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:33 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:33 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:35 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:04:36 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:04:36 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:04:36 Benchmarks for the generation speed, input length : 32, output_length : 16, nb_requests : 38 : DONE
INFO:Benchmark suite:2024-11-22, 11:04:36 Benchmarks for the generation speed, input length : 32, output_length : 16 : DONE
INFO:Benchmark suite:2024-11-22, 11:04:36 Beginning the benchmarks for the generation speed, input length : 32, output_length : 128
INFO:Benchmark suite:2024-11-22, 11:04:36 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 1
INFO:Benchmark for LLMs:2024-11-22, 11:04:36 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:04:36 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:06:54 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:09:09 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:09:42 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:09:42 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:09:42 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 1 : DONE
INFO:Benchmark suite:2024-11-22, 11:09:42 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 2
INFO:Benchmark for LLMs:2024-11-22, 11:09:42 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:09:42 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:10:58 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:12:10 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:13:23 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:14:36 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:14:49 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:14:49 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:14:49 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 2 : DONE
INFO:Benchmark suite:2024-11-22, 11:14:49 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 3
INFO:Benchmark for LLMs:2024-11-22, 11:14:49 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:14:49 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:15:41 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:16:29 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:17:18 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:18:08 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:18:56 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:19:45 600 queries have been completed
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-984756' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ServerDisconnectedError('Server disconnected')>
Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ServerDisconnectedError: Server disconnected
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-984762' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ServerDisconnectedError('Server disconnected')>
Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ServerDisconnectedError: Server disconnected
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-984764' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ServerDisconnectedError('Server disconnected')>
Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ServerDisconnectedError: Server disconnected
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-984758' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ServerDisconnectedError('Server disconnected')>
Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ServerDisconnectedError: Server disconnected
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-984760' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ServerDisconnectedError('Server disconnected')>
Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ServerDisconnectedError: Server disconnected
INFO:Benchmark for LLMs:2024-11-22, 11:19:56 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:19:56 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:19:56 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 3 : DONE
INFO:Benchmark suite:2024-11-22, 11:19:56 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 4
INFO:Benchmark for LLMs:2024-11-22, 11:19:56 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:19:56 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:20:35 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:21:12 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:21:48 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:22:25 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:23:01 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:23:38 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:24:16 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:24:52 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:25:03 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:25:03 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:25:03 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 4 : DONE
INFO:Benchmark suite:2024-11-22, 11:25:03 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 6
INFO:Benchmark for LLMs:2024-11-22, 11:25:03 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:25:03 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:25:31 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:25:56 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:26:20 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:26:45 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:27:10 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:27:34 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:27:59 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:28:24 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:28:48 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:29:13 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:29:14 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:29:14 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:29:14 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 6 : DONE
INFO:Benchmark suite:2024-11-22, 11:29:14 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 8
INFO:Benchmark for LLMs:2024-11-22, 11:29:14 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:29:14 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:29:36 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:29:54 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:30:13 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:30:31 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:30:50 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:31:08 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:31:28 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:31:45 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:32:05 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:32:22 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:32:23 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:32:23 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:32:23 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 8 : DONE
INFO:Benchmark suite:2024-11-22, 11:32:23 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 10
INFO:Benchmark for LLMs:2024-11-22, 11:32:23 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:32:23 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:32:42 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:32:57 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:33:13 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:33:28 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:33:44 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:33:59 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:34:15 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:34:30 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:34:46 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:35:01 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:35:02 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:35:02 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:35:02 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 10 : DONE
INFO:Benchmark suite:2024-11-22, 11:35:02 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 14
INFO:Benchmark for LLMs:2024-11-22, 11:35:02 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:35:02 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:35:18 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:35:29 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:35:41 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:35:52 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:36:03 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:36:15 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:36:26 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:36:39 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:36:51 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:37:02 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:37:03 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:37:04 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:37:04 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 14 : DONE
INFO:Benchmark suite:2024-11-22, 11:37:04 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 18
INFO:Benchmark for LLMs:2024-11-22, 11:37:04 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:37:04 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:37:15 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:37:25 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:37:33 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:37:42 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:37:51 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:38:01 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:38:08 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:38:18 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:38:26 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:38:36 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:38:37 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:38:37 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:38:37 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 18 : DONE
INFO:Benchmark suite:2024-11-22, 11:38:37 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 22
INFO:Benchmark for LLMs:2024-11-22, 11:38:37 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:38:37 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:38:48 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:38:56 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:39:03 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:39:12 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:39:19 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:39:27 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:39:34 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:39:42 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:39:49 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:39:58 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:39:59 Requests to the completions endpoint done
WARNING:Benchmark for LLMs:2024-11-22, 11:39:59 There are 1 queries in error including 0 queries in timeout
INFO:Benchmark for LLMs:2024-11-22, 11:39:59 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:39:59 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 22 : DONE
INFO:Benchmark suite:2024-11-22, 11:39:59 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 26
INFO:Benchmark for LLMs:2024-11-22, 11:39:59 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:39:59 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:40:08 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:40:16 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:40:23 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:40:30 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:40:37 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:40:44 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:40:50 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:40:57 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:41:04 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:41:11 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:41:12 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:41:12 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:41:13 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 26 : DONE
INFO:Benchmark suite:2024-11-22, 11:41:13 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 30
INFO:Benchmark for LLMs:2024-11-22, 11:41:13 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:41:13 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:41:22 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:41:28 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:41:33 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:41:41 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:41:47 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:41:52 600 queries have been completed
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1251626' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1251622' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1251624' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1251620' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1251618' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1251616' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
INFO:Benchmark for LLMs:2024-11-22, 11:42:01 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:42:06 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:42:12 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:42:19 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:42:20 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:42:20 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:42:20 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 30 : DONE
INFO:Benchmark suite:2024-11-22, 11:42:20 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 34
INFO:Benchmark for LLMs:2024-11-22, 11:42:20 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:42:20 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:42:29 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:42:35 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:42:41 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:42:46 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:42:53 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:42:59 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:43:05 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:43:11 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:43:17 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:43:23 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:43:24 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:43:24 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:43:24 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 34 : DONE
INFO:Benchmark suite:2024-11-22, 11:43:24 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 38
INFO:Benchmark for LLMs:2024-11-22, 11:43:24 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:43:24 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:43:32 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:43:39 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:43:43 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:43:49 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:43:56 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:44:00 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:44:06 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:44:13 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:44:17 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:44:23 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 11:44:24 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:44:24 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:44:24 Benchmarks for the generation speed, input length : 32, output_length : 128, nb_requests : 38 : DONE
INFO:Benchmark suite:2024-11-22, 11:44:24 Benchmarks for the generation speed, input length : 32, output_length : 128 : DONE
INFO:Benchmark suite:2024-11-22, 11:44:24 Beginning the benchmarks for the generation speed, input length : 32, output_length : 1024
INFO:Benchmark suite:2024-11-22, 11:44:24 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 1
INFO:Benchmark for LLMs:2024-11-22, 11:44:24 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:44:24 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 11:55:41 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 11:55:41 Derived calculations done
INFO:Benchmark suite:2024-11-22, 11:55:41 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 1 : DONE
INFO:Benchmark suite:2024-11-22, 11:55:41 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 2
INFO:Benchmark for LLMs:2024-11-22, 11:55:41 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 11:55:41 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 12:01:29 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 12:01:29 Derived calculations done
INFO:Benchmark suite:2024-11-22, 12:01:29 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 2 : DONE
INFO:Benchmark suite:2024-11-22, 12:01:29 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 3
INFO:Benchmark for LLMs:2024-11-22, 12:01:29 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 12:01:29 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 12:07:07 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 12:07:07 Derived calculations done
INFO:Benchmark suite:2024-11-22, 12:07:07 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 3 : DONE
INFO:Benchmark suite:2024-11-22, 12:07:07 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 4
INFO:Benchmark for LLMs:2024-11-22, 12:07:07 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 12:07:07 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 12:12:00 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:12:45 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 12:12:45 Derived calculations done
INFO:Benchmark suite:2024-11-22, 12:12:45 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 4 : DONE
INFO:Benchmark suite:2024-11-22, 12:12:45 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 6
INFO:Benchmark for LLMs:2024-11-22, 12:12:45 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 12:12:45 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 12:16:18 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:18:28 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 12:18:29 Derived calculations done
INFO:Benchmark suite:2024-11-22, 12:18:29 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 6 : DONE
INFO:Benchmark suite:2024-11-22, 12:18:29 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 8
INFO:Benchmark for LLMs:2024-11-22, 12:18:29 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 12:18:29 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 12:21:19 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:23:48 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:24:11 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 12:24:11 Derived calculations done
INFO:Benchmark suite:2024-11-22, 12:24:11 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 8 : DONE
INFO:Benchmark suite:2024-11-22, 12:24:11 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 10
INFO:Benchmark for LLMs:2024-11-22, 12:24:11 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 12:24:12 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 12:26:35 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:28:46 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:29:51 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 12:29:51 Derived calculations done
INFO:Benchmark suite:2024-11-22, 12:29:51 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 10 : DONE
INFO:Benchmark suite:2024-11-22, 12:29:51 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 14
INFO:Benchmark for LLMs:2024-11-22, 12:29:51 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 12:29:51 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 12:31:54 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:33:33 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:35:11 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:35:37 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 12:35:37 Derived calculations done
INFO:Benchmark suite:2024-11-22, 12:35:37 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 14 : DONE
INFO:Benchmark suite:2024-11-22, 12:35:37 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 18
INFO:Benchmark for LLMs:2024-11-22, 12:35:37 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 12:35:37 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 12:37:16 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:38:45 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:39:59 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:41:23 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 12:41:23 Derived calculations done
INFO:Benchmark suite:2024-11-22, 12:41:23 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 18 : DONE
INFO:Benchmark suite:2024-11-22, 12:41:23 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 22
INFO:Benchmark for LLMs:2024-11-22, 12:41:23 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 12:41:23 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 12:42:50 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:44:07 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:45:08 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:46:24 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:47:06 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 12:47:06 Derived calculations done
INFO:Benchmark suite:2024-11-22, 12:47:06 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 22 : DONE
INFO:Benchmark suite:2024-11-22, 12:47:06 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 26
INFO:Benchmark for LLMs:2024-11-22, 12:47:06 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 12:47:06 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 12:48:21 100 queries have been completed
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1969215' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1969217' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1969213' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
INFO:Benchmark for LLMs:2024-11-22, 12:49:25 200 queries have been completed
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1978562' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1978558' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1978556' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1978560' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1978554' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1978550' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1978548' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1978552' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1978546' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1978544' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1978542' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1978540' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1978536' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1978538' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1978534' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-1978532' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
INFO:Benchmark for LLMs:2024-11-22, 12:50:30 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:51:34 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:52:38 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:52:50 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 12:52:50 Derived calculations done
INFO:Benchmark suite:2024-11-22, 12:52:50 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 26 : DONE
INFO:Benchmark suite:2024-11-22, 12:52:50 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 30
INFO:Benchmark for LLMs:2024-11-22, 12:52:50 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 12:52:50 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 12:54:12 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:55:04 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:55:56 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:57:06 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:57:58 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 12:58:44 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 12:58:44 Derived calculations done
INFO:Benchmark suite:2024-11-22, 12:58:44 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 30 : DONE
INFO:Benchmark suite:2024-11-22, 12:58:44 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 34
INFO:Benchmark for LLMs:2024-11-22, 12:58:44 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 12:58:44 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 12:59:51 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:00:46 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:01:42 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:02:38 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:03:33 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:04:28 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:04:39 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:04:40 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:04:40 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 34 : DONE
INFO:Benchmark suite:2024-11-22, 13:04:40 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 38
INFO:Benchmark for LLMs:2024-11-22, 13:04:40 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:04:40 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:05:48 100 queries have been completed
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160038' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160042' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160040' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160036' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160034' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160032' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160030' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160028' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160026' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160024' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160020' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160018' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160022' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160014' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160016' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160012' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160008' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160006' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160010' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160004' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160002' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2160000' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2159998' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2159996' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2159994' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2159992' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2159990' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
INFO:Benchmark for LLMs:2024-11-22, 13:06:45 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:07:23 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:08:20 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:09:17 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:09:56 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:10:26 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:10:26 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:10:26 Benchmarks for the generation speed, input length : 32, output_length : 1024, nb_requests : 38 : DONE
INFO:Benchmark suite:2024-11-22, 13:10:26 Benchmarks for the generation speed, input length : 32, output_length : 1024 : DONE
INFO:Benchmark suite:2024-11-22, 13:10:26 Beginning the benchmarks for the generation speed, input length : 1024, output_length : 16
INFO:Benchmark suite:2024-11-22, 13:10:26 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 1
INFO:Benchmark for LLMs:2024-11-22, 13:10:26 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:10:26 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:10:51 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:11:13 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:11:36 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:11:59 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:12:22 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:12:44 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:13:07 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:13:30 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:13:52 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:14:16 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:14:17 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:14:17 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:14:17 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 1 : DONE
INFO:Benchmark suite:2024-11-22, 13:14:17 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 2
INFO:Benchmark for LLMs:2024-11-22, 13:14:17 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:14:17 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:14:33 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:14:47 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:15:02 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:15:17 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:15:32 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:15:47 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:16:01 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:16:17 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:16:31 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:16:46 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:16:47 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:16:47 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:16:47 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 2 : DONE
INFO:Benchmark suite:2024-11-22, 13:16:47 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 3
INFO:Benchmark for LLMs:2024-11-22, 13:16:47 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:16:47 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:17:00 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:17:12 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:17:24 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:17:35 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:17:47 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:17:58 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:18:10 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:18:22 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:18:33 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:18:45 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:18:46 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:18:46 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:18:46 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 3 : DONE
INFO:Benchmark suite:2024-11-22, 13:18:46 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 4
INFO:Benchmark for LLMs:2024-11-22, 13:18:46 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:18:46 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:18:57 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:19:07 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:19:18 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:19:28 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:19:38 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:19:48 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:19:58 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:20:08 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:20:18 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:20:29 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:20:30 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:20:30 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:20:30 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 4 : DONE
INFO:Benchmark suite:2024-11-22, 13:20:30 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 6
INFO:Benchmark for LLMs:2024-11-22, 13:20:30 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:20:30 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:20:40 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:20:49 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:20:57 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:21:06 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:21:15 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:21:23 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:21:32 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:21:41 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:21:49 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:21:58 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:21:59 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:21:59 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:21:59 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 6 : DONE
INFO:Benchmark suite:2024-11-22, 13:21:59 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 8
INFO:Benchmark for LLMs:2024-11-22, 13:21:59 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:21:59 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:22:08 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:22:16 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:22:25 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:22:32 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:22:40 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:22:48 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:22:56 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:23:04 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:23:12 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:23:20 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:23:21 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:23:21 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:23:21 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 8 : DONE
INFO:Benchmark suite:2024-11-22, 13:23:21 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 10
INFO:Benchmark for LLMs:2024-11-22, 13:23:21 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:23:21 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:23:30 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:23:37 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:23:45 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:23:52 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:24:00 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:24:07 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:24:15 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:24:23 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:24:31 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:24:38 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:24:40 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:24:40 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:24:40 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 10 : DONE
INFO:Benchmark suite:2024-11-22, 13:24:40 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 14
INFO:Benchmark for LLMs:2024-11-22, 13:24:40 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:24:40 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:24:49 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:24:55 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:25:02 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:25:09 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:25:16 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:25:23 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:25:30 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:25:37 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:25:44 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:25:50 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:25:52 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:25:52 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:25:52 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 14 : DONE
INFO:Benchmark suite:2024-11-22, 13:25:52 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 18
INFO:Benchmark for LLMs:2024-11-22, 13:25:52 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:25:52 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:26:00 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:26:07 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:26:13 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:26:20 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:26:26 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:26:34 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:26:40 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:26:47 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:26:53 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:27:00 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:27:01 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:27:01 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:27:01 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 18 : DONE
INFO:Benchmark suite:2024-11-22, 13:27:01 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 22
INFO:Benchmark for LLMs:2024-11-22, 13:27:01 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:27:01 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:27:09 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:27:16 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:27:22 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:27:29 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:27:35 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:27:42 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:27:48 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:27:56 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:28:01 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:28:08 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:28:09 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:28:09 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:28:09 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 22 : DONE
INFO:Benchmark suite:2024-11-22, 13:28:09 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 26
INFO:Benchmark for LLMs:2024-11-22, 13:28:09 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:28:09 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:28:17 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:28:23 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:28:30 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:28:37 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:28:43 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:28:50 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:28:55 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:29:01 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:29:09 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:29:14 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:29:16 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:29:16 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:29:16 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 26 : DONE
INFO:Benchmark suite:2024-11-22, 13:29:16 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 30
INFO:Benchmark for LLMs:2024-11-22, 13:29:16 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:29:16 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:29:24 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:29:30 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:29:36 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:29:44 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:29:49 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:29:55 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:30:03 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:30:09 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:30:14 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:30:21 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:30:22 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:30:22 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:30:22 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 30 : DONE
INFO:Benchmark suite:2024-11-22, 13:30:22 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 34
INFO:Benchmark for LLMs:2024-11-22, 13:30:22 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:30:22 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:30:29 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:30:36 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:30:42 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:30:49 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:30:55 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:31:02 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:31:08 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:31:14 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:31:21 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:31:26 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:31:27 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:31:27 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:31:27 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 34 : DONE
INFO:Benchmark suite:2024-11-22, 13:31:27 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 38
INFO:Benchmark for LLMs:2024-11-22, 13:31:27 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:31:27 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:31:35 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:31:42 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:31:47 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:31:54 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:32:01 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:32:06 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:32:13 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:32:20 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:32:24 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:32:30 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:32:31 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:32:32 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:32:32 Benchmarks for the generation speed, input length : 1024, output_length : 16, nb_requests : 38 : DONE
INFO:Benchmark suite:2024-11-22, 13:32:32 Benchmarks for the generation speed, input length : 1024, output_length : 16 : DONE
INFO:Benchmark suite:2024-11-22, 13:32:32 Beginning the benchmarks for the generation speed, input length : 1024, output_length : 128
INFO:Benchmark suite:2024-11-22, 13:32:32 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 1
INFO:Benchmark for LLMs:2024-11-22, 13:32:32 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:32:32 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:34:58 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:37:23 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:37:38 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:37:38 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:37:38 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 1 : DONE
INFO:Benchmark suite:2024-11-22, 13:37:38 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 2
INFO:Benchmark for LLMs:2024-11-22, 13:37:38 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:37:38 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:38:56 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:40:12 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:41:29 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:42:45 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:42:45 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:42:45 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 2 : DONE
INFO:Benchmark suite:2024-11-22, 13:42:45 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 3
INFO:Benchmark for LLMs:2024-11-22, 13:42:45 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:42:45 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:43:41 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:44:32 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:45:24 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:46:17 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:47:10 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:47:52 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:47:52 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:47:52 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 3 : DONE
INFO:Benchmark suite:2024-11-22, 13:47:52 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 4
INFO:Benchmark for LLMs:2024-11-22, 13:47:52 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:47:52 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:48:35 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:49:16 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:49:57 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:50:38 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:51:20 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:52:01 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:52:42 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:52:59 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:52:59 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:52:59 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 4 : DONE
INFO:Benchmark suite:2024-11-22, 13:52:59 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 6
INFO:Benchmark for LLMs:2024-11-22, 13:52:59 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:52:59 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:53:34 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:54:07 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:54:37 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:55:10 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:55:42 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:56:13 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:56:45 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:57:18 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:57:49 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:58:07 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 13:58:07 Derived calculations done
INFO:Benchmark suite:2024-11-22, 13:58:07 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 6 : DONE
INFO:Benchmark suite:2024-11-22, 13:58:07 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 8
INFO:Benchmark for LLMs:2024-11-22, 13:58:07 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 13:58:07 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 13:58:36 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:59:02 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:59:30 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 13:59:55 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:00:22 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:00:48 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:01:16 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:01:42 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:02:09 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:02:35 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:02:36 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 14:02:36 Derived calculations done
INFO:Benchmark suite:2024-11-22, 14:02:36 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 8 : DONE
INFO:Benchmark suite:2024-11-22, 14:02:36 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 10
INFO:Benchmark for LLMs:2024-11-22, 14:02:36 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 14:02:36 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 14:03:02 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:03:26 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:03:50 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:04:14 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:04:38 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:05:02 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:05:26 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:05:49 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:06:13 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:06:37 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:06:38 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 14:06:38 Derived calculations done
INFO:Benchmark suite:2024-11-22, 14:06:38 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 10 : DONE
INFO:Benchmark suite:2024-11-22, 14:06:38 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 14
INFO:Benchmark for LLMs:2024-11-22, 14:06:38 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 14:06:38 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 14:07:02 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:07:21 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:07:40 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:07:59 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:08:18 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:08:37 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:08:56 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:09:18 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:09:37 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:09:56 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:09:57 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 14:09:57 Derived calculations done
INFO:Benchmark suite:2024-11-22, 14:09:57 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 14 : DONE
INFO:Benchmark suite:2024-11-22, 14:09:57 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 18
INFO:Benchmark for LLMs:2024-11-22, 14:09:57 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 14:09:57 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 14:10:18 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:10:37 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:10:52 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:11:11 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:11:27 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:11:45 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:12:01 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:12:19 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:12:35 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:12:53 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:12:54 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 14:12:54 Derived calculations done
INFO:Benchmark suite:2024-11-22, 14:12:54 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 18 : DONE
INFO:Benchmark suite:2024-11-22, 14:12:54 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 22
INFO:Benchmark for LLMs:2024-11-22, 14:12:54 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 14:12:54 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 14:13:13 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:13:30 200 queries have been completed
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-2967814' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
INFO:Benchmark for LLMs:2024-11-22, 14:13:45 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:14:02 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:14:15 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:14:33 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:14:47 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:15:04 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:15:17 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:15:34 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:15:35 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 14:15:35 Derived calculations done
INFO:Benchmark suite:2024-11-22, 14:15:35 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 22 : DONE
INFO:Benchmark suite:2024-11-22, 14:15:35 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 26
INFO:Benchmark for LLMs:2024-11-22, 14:15:35 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 14:15:35 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 14:15:53 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:16:08 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:16:23 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:16:38 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:16:54 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:17:09 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:17:21 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:17:36 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:17:51 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:18:05 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:18:06 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 14:18:06 Derived calculations done
INFO:Benchmark suite:2024-11-22, 14:18:06 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 26 : DONE
INFO:Benchmark suite:2024-11-22, 14:18:06 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 30
INFO:Benchmark for LLMs:2024-11-22, 14:18:06 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 14:18:06 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 14:18:26 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:18:39 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:18:52 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:19:10 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:19:23 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:19:36 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:19:54 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:20:07 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:20:20 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:20:35 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:20:36 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 14:20:36 Derived calculations done
INFO:Benchmark suite:2024-11-22, 14:20:36 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 30 : DONE
INFO:Benchmark suite:2024-11-22, 14:20:36 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 34
INFO:Benchmark for LLMs:2024-11-22, 14:20:36 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 14:20:36 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 14:20:53 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:21:07 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:21:20 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:21:34 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:21:48 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:22:02 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:22:16 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:22:29 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:22:43 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:22:55 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:22:56 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 14:22:56 Derived calculations done
INFO:Benchmark suite:2024-11-22, 14:22:56 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 34 : DONE
INFO:Benchmark suite:2024-11-22, 14:22:56 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 38
INFO:Benchmark for LLMs:2024-11-22, 14:22:56 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 14:22:56 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 14:23:13 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:23:28 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:23:38 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:23:53 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:24:08 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:24:18 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:24:32 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:24:47 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:24:57 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:25:10 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:25:11 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 14:25:11 Derived calculations done
INFO:Benchmark suite:2024-11-22, 14:25:11 Benchmarks for the generation speed, input length : 1024, output_length : 128, nb_requests : 38 : DONE
INFO:Benchmark suite:2024-11-22, 14:25:11 Benchmarks for the generation speed, input length : 1024, output_length : 128 : DONE
INFO:Benchmark suite:2024-11-22, 14:25:11 Beginning the benchmarks for the generation speed, input length : 1024, output_length : 1024
INFO:Benchmark suite:2024-11-22, 14:25:11 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 1
INFO:Benchmark for LLMs:2024-11-22, 14:25:11 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 14:25:11 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 14:36:33 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 14:36:33 Derived calculations done
INFO:Benchmark suite:2024-11-22, 14:36:33 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 1 : DONE
INFO:Benchmark suite:2024-11-22, 14:36:33 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 2
INFO:Benchmark for LLMs:2024-11-22, 14:36:33 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 14:36:33 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 14:42:24 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 14:42:24 Derived calculations done
INFO:Benchmark suite:2024-11-22, 14:42:24 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 2 : DONE
INFO:Benchmark suite:2024-11-22, 14:42:24 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 3
INFO:Benchmark for LLMs:2024-11-22, 14:42:24 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 14:42:24 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 14:47:59 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 14:47:59 Derived calculations done
INFO:Benchmark suite:2024-11-22, 14:47:59 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 3 : DONE
INFO:Benchmark suite:2024-11-22, 14:47:59 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 4
INFO:Benchmark for LLMs:2024-11-22, 14:47:59 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 14:47:59 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 14:53:11 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:53:35 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 14:53:35 Derived calculations done
INFO:Benchmark suite:2024-11-22, 14:53:35 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 4 : DONE
INFO:Benchmark suite:2024-11-22, 14:53:35 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 6
INFO:Benchmark for LLMs:2024-11-22, 14:53:35 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 14:53:35 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 14:57:43 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 14:59:18 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 14:59:18 Derived calculations done
INFO:Benchmark suite:2024-11-22, 14:59:18 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 6 : DONE
INFO:Benchmark suite:2024-11-22, 14:59:18 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 8
INFO:Benchmark for LLMs:2024-11-22, 14:59:18 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 14:59:18 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 15:02:42 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:05:07 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 15:05:07 Derived calculations done
INFO:Benchmark suite:2024-11-22, 15:05:07 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 8 : DONE
INFO:Benchmark suite:2024-11-22, 15:05:07 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 10
INFO:Benchmark for LLMs:2024-11-22, 15:05:07 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 15:05:07 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 15:08:02 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:10:44 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:10:55 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 15:10:55 Derived calculations done
INFO:Benchmark suite:2024-11-22, 15:10:55 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 10 : DONE
INFO:Benchmark suite:2024-11-22, 15:10:55 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 14
INFO:Benchmark for LLMs:2024-11-22, 15:10:55 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 15:10:55 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 15:13:32 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:15:40 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:16:46 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 15:16:46 Derived calculations done
INFO:Benchmark suite:2024-11-22, 15:16:46 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 14 : DONE
INFO:Benchmark suite:2024-11-22, 15:16:46 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 18
INFO:Benchmark for LLMs:2024-11-22, 15:16:46 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 15:16:46 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 15:19:03 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:21:09 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:22:44 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 15:22:44 Derived calculations done
INFO:Benchmark suite:2024-11-22, 15:22:44 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 18 : DONE
INFO:Benchmark suite:2024-11-22, 15:22:44 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 22
INFO:Benchmark for LLMs:2024-11-22, 15:22:44 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 15:22:44 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 15:24:46 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:26:37 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:28:06 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:28:39 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 15:28:39 Derived calculations done
INFO:Benchmark suite:2024-11-22, 15:28:39 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 22 : DONE
INFO:Benchmark suite:2024-11-22, 15:28:39 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 26
INFO:Benchmark for LLMs:2024-11-22, 15:28:39 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 15:28:39 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 15:30:26 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:32:03 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:33:38 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:34:38 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 15:34:38 Derived calculations done
INFO:Benchmark suite:2024-11-22, 15:34:38 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 26 : DONE
INFO:Benchmark suite:2024-11-22, 15:34:38 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 30
INFO:Benchmark for LLMs:2024-11-22, 15:34:38 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 15:34:38 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 15:36:38 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:37:59 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:39:20 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:40:53 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 15:40:53 Derived calculations done
INFO:Benchmark suite:2024-11-22, 15:40:53 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 30 : DONE
INFO:Benchmark suite:2024-11-22, 15:40:53 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 34
INFO:Benchmark for LLMs:2024-11-22, 15:40:53 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 15:40:53 Beginning the requests to the completions endpoint
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-3919647' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-3919643' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-3919641' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-3919645' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-3919639' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
INFO:Benchmark for LLMs:2024-11-22, 15:42:30 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:43:56 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:45:22 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:46:49 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:47:01 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 15:47:01 Derived calculations done
INFO:Benchmark suite:2024-11-22, 15:47:01 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 34 : DONE
INFO:Benchmark suite:2024-11-22, 15:47:01 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 38
INFO:Benchmark for LLMs:2024-11-22, 15:47:01 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 15:47:01 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 15:48:43 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:50:17 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:51:18 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:52:49 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:53:01 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 15:53:01 Derived calculations done
INFO:Benchmark suite:2024-11-22, 15:53:01 Benchmarks for the generation speed, input length : 1024, output_length : 1024, nb_requests : 38 : DONE
INFO:Benchmark suite:2024-11-22, 15:53:01 Benchmarks for the generation speed, input length : 1024, output_length : 1024 : DONE
INFO:Benchmark suite:2024-11-22, 15:53:01 Beginning the benchmarks for the generation speed, input length : 4096, output_length : 16
INFO:Benchmark suite:2024-11-22, 15:53:01 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 1
INFO:Benchmark for LLMs:2024-11-22, 15:53:01 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 15:53:01 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 15:53:42 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:54:22 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:55:02 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:55:42 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:56:22 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:57:02 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:57:42 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:58:04 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 15:58:04 Derived calculations done
INFO:Benchmark suite:2024-11-22, 15:58:04 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 1 : DONE
INFO:Benchmark suite:2024-11-22, 15:58:04 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 2
INFO:Benchmark for LLMs:2024-11-22, 15:58:04 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 15:58:04 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 15:58:38 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:59:10 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 15:59:42 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:00:14 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:00:46 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:01:19 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:01:51 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:02:23 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:02:55 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:03:08 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 16:03:08 Derived calculations done
INFO:Benchmark suite:2024-11-22, 16:03:08 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 2 : DONE
INFO:Benchmark suite:2024-11-22, 16:03:08 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 3
INFO:Benchmark for LLMs:2024-11-22, 16:03:08 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 16:03:08 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 16:03:39 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:04:08 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:04:37 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:05:07 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:05:35 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:06:04 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:06:34 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:07:03 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:07:31 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:08:00 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:08:02 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 16:08:02 Derived calculations done
INFO:Benchmark suite:2024-11-22, 16:08:02 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 3 : DONE
INFO:Benchmark suite:2024-11-22, 16:08:02 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 4
INFO:Benchmark for LLMs:2024-11-22, 16:08:02 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 16:08:02 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 16:08:30 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:08:58 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:09:25 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:09:52 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:10:20 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:10:48 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:11:15 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:11:42 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:12:10 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:12:37 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:12:38 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 16:12:38 Derived calculations done
INFO:Benchmark suite:2024-11-22, 16:12:38 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 4 : DONE
INFO:Benchmark suite:2024-11-22, 16:12:38 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 6
INFO:Benchmark for LLMs:2024-11-22, 16:12:38 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 16:12:38 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 16:13:06 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:13:33 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:13:58 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:14:24 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:14:51 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:15:17 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:15:44 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:16:10 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:16:35 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:17:01 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:17:02 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 16:17:02 Derived calculations done
INFO:Benchmark suite:2024-11-22, 16:17:02 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 6 : DONE
INFO:Benchmark suite:2024-11-22, 16:17:02 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 8
INFO:Benchmark for LLMs:2024-11-22, 16:17:02 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 16:17:02 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 16:17:29 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:17:54 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:18:20 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:18:44 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:19:11 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:19:35 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:20:01 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:20:26 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:20:52 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:21:16 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:21:17 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 16:21:17 Derived calculations done
INFO:Benchmark suite:2024-11-22, 16:21:18 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 8 : DONE
INFO:Benchmark suite:2024-11-22, 16:21:18 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 10
INFO:Benchmark for LLMs:2024-11-22, 16:21:18 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 16:21:18 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 16:21:43 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:22:08 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:22:33 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:22:58 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:23:23 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:23:47 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:24:12 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:24:37 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:25:02 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:25:26 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:25:27 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 16:25:27 Derived calculations done
INFO:Benchmark suite:2024-11-22, 16:25:27 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 10 : DONE
INFO:Benchmark suite:2024-11-22, 16:25:27 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 14
INFO:Benchmark for LLMs:2024-11-22, 16:25:27 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 16:25:27 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 16:25:56 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:26:19 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:26:43 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:27:07 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:27:31 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:27:55 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:28:18 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:28:46 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:29:09 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:29:31 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:29:32 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 16:29:32 Derived calculations done
INFO:Benchmark suite:2024-11-22, 16:29:32 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 14 : DONE
INFO:Benchmark suite:2024-11-22, 16:29:32 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 18
INFO:Benchmark for LLMs:2024-11-22, 16:29:32 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 16:29:32 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 16:29:59 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:30:25 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:30:48 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:31:14 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:31:36 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:32:02 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:32:23 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:32:49 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:33:11 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:33:35 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:33:36 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 16:33:36 Derived calculations done
INFO:Benchmark suite:2024-11-22, 16:33:36 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 18 : DONE
INFO:Benchmark suite:2024-11-22, 16:33:36 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 22
INFO:Benchmark for LLMs:2024-11-22, 16:33:36 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 16:33:36 Beginning the requests to the completions endpoint
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-4528397' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
INFO:Benchmark for LLMs:2024-11-22, 16:34:04 100 queries have been completed
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-4532543' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-4536837' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
INFO:Benchmark for LLMs:2024-11-22, 16:34:30 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:34:51 300 queries have been completed
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-4542078' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-4542077' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-4542076' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-4542075' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
INFO:Benchmark for LLMs:2024-11-22, 16:35:18 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:35:39 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:36:05 600 queries have been completed
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-4557818' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-4557817' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
INFO:Benchmark for LLMs:2024-11-22, 16:36:26 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:36:52 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:37:13 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:37:35 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:37:36 Requests to the completions endpoint done
WARNING:Benchmark for LLMs:2024-11-22, 16:37:36 There are 7 queries in error including 0 queries in timeout
INFO:Benchmark for LLMs:2024-11-22, 16:37:36 Derived calculations done
INFO:Benchmark suite:2024-11-22, 16:37:36 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 22 : DONE
INFO:Benchmark suite:2024-11-22, 16:37:36 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 26
INFO:Benchmark for LLMs:2024-11-22, 16:37:36 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 16:37:36 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 16:38:01 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:38:26 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:38:50 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:39:16 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:39:40 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:40:05 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:40:23 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:40:47 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:41:13 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:41:34 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:41:35 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 16:41:36 Derived calculations done
INFO:Benchmark suite:2024-11-22, 16:41:36 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 26 : DONE
INFO:Benchmark suite:2024-11-22, 16:41:36 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 30
INFO:Benchmark for LLMs:2024-11-22, 16:41:36 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 16:41:36 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 16:42:06 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:42:27 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:42:48 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:43:17 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:43:38 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:44:00 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:44:28 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:44:49 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:45:10 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:45:35 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:45:36 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 16:45:36 Derived calculations done
INFO:Benchmark suite:2024-11-22, 16:45:36 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 30 : DONE
INFO:Benchmark suite:2024-11-22, 16:45:36 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 34
INFO:Benchmark for LLMs:2024-11-22, 16:45:36 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 16:45:36 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 16:46:05 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:46:26 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:46:48 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:47:16 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:47:37 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:47:58 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:48:27 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:48:48 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:49:09 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:49:34 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:49:35 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 16:49:35 Derived calculations done
INFO:Benchmark suite:2024-11-22, 16:49:35 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 34 : DONE
INFO:Benchmark suite:2024-11-22, 16:49:35 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 38
INFO:Benchmark for LLMs:2024-11-22, 16:49:35 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 16:49:35 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 16:50:05 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:50:26 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:50:47 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:51:15 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:51:37 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:51:58 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:52:26 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:52:47 800 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:53:09 900 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:53:33 1000 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:53:34 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 16:53:34 Derived calculations done
INFO:Benchmark suite:2024-11-22, 16:53:34 Benchmarks for the generation speed, input length : 4096, output_length : 16, nb_requests : 38 : DONE
INFO:Benchmark suite:2024-11-22, 16:53:34 Benchmarks for the generation speed, input length : 4096, output_length : 16 : DONE
INFO:Benchmark suite:2024-11-22, 16:53:34 Beginning the benchmarks for the generation speed, input length : 4096, output_length : 128
INFO:Benchmark suite:2024-11-22, 16:53:34 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 1
INFO:Benchmark for LLMs:2024-11-22, 16:53:34 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 16:53:34 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 16:56:17 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 16:58:42 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 16:58:42 Derived calculations done
INFO:Benchmark suite:2024-11-22, 16:58:42 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 1 : DONE
INFO:Benchmark suite:2024-11-22, 16:58:42 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 2
INFO:Benchmark for LLMs:2024-11-22, 16:58:42 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 16:58:42 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 17:00:23 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:02:01 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:03:40 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:03:50 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 17:03:50 Derived calculations done
INFO:Benchmark suite:2024-11-22, 17:03:50 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 2 : DONE
INFO:Benchmark suite:2024-11-22, 17:03:50 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 3
INFO:Benchmark for LLMs:2024-11-22, 17:03:50 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 17:03:50 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 17:05:13 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:06:31 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:07:48 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:08:57 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 17:08:58 Derived calculations done
INFO:Benchmark suite:2024-11-22, 17:08:58 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 3 : DONE
INFO:Benchmark suite:2024-11-22, 17:08:58 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 4
INFO:Benchmark for LLMs:2024-11-22, 17:08:58 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 17:08:58 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 17:10:07 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:11:15 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:12:22 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:13:31 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:14:06 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 17:14:06 Derived calculations done
INFO:Benchmark suite:2024-11-22, 17:14:06 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 4 : DONE
INFO:Benchmark suite:2024-11-22, 17:14:06 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 6
INFO:Benchmark for LLMs:2024-11-22, 17:14:06 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 17:14:06 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 17:15:07 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:16:07 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:17:02 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:18:02 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:19:01 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:19:17 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 17:19:17 Derived calculations done
INFO:Benchmark suite:2024-11-22, 17:19:17 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 6 : DONE
INFO:Benchmark suite:2024-11-22, 17:19:17 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 8
INFO:Benchmark for LLMs:2024-11-22, 17:19:17 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 17:19:17 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 17:20:14 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:21:05 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:21:59 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:22:49 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:23:44 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:24:29 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 17:24:29 Derived calculations done
INFO:Benchmark suite:2024-11-22, 17:24:29 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 8 : DONE
INFO:Benchmark suite:2024-11-22, 17:24:29 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 10
INFO:Benchmark for LLMs:2024-11-22, 17:24:29 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 17:24:29 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 17:25:20 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:26:09 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:26:58 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:27:47 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:28:36 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:29:26 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:29:39 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 17:29:39 Derived calculations done
INFO:Benchmark suite:2024-11-22, 17:29:39 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 10 : DONE
INFO:Benchmark suite:2024-11-22, 17:29:39 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 14
INFO:Benchmark for LLMs:2024-11-22, 17:29:39 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 17:29:39 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 17:30:32 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:31:16 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:32:01 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:32:45 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:33:29 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:34:14 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:34:54 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 17:34:54 Derived calculations done
INFO:Benchmark suite:2024-11-22, 17:34:54 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 14 : DONE
INFO:Benchmark suite:2024-11-22, 17:34:54 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 18
INFO:Benchmark for LLMs:2024-11-22, 17:34:54 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 17:34:54 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 17:35:44 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:36:33 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:37:13 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:38:01 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:38:42 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:39:30 600 queries have been completed
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-5290740' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-5290738' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
INFO:Benchmark for LLMs:2024-11-22, 17:40:10 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:40:13 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 17:40:13 Derived calculations done
INFO:Benchmark suite:2024-11-22, 17:40:13 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 18 : DONE
INFO:Benchmark suite:2024-11-22, 17:40:13 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 22
INFO:Benchmark for LLMs:2024-11-22, 17:40:13 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 17:40:13 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 17:41:02 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:41:48 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:42:25 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:43:12 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:43:49 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:44:36 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:45:12 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:45:34 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 17:45:35 Derived calculations done
INFO:Benchmark suite:2024-11-22, 17:45:35 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 22 : DONE
INFO:Benchmark suite:2024-11-22, 17:45:35 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 26
INFO:Benchmark for LLMs:2024-11-22, 17:45:35 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 17:45:35 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 17:46:19 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:47:02 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:47:45 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:48:27 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:49:10 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:49:53 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:50:24 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:50:59 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 17:50:59 Derived calculations done
INFO:Benchmark suite:2024-11-22, 17:50:59 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 26 : DONE
INFO:Benchmark suite:2024-11-22, 17:50:59 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 30
INFO:Benchmark for LLMs:2024-11-22, 17:50:59 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 17:50:59 Beginning the requests to the completions endpoint
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-5425254' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
INFO:Benchmark for LLMs:2024-11-22, 17:51:51 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:52:29 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:53:12 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:53:55 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:54:32 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:55:15 600 queries have been completed
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-5470243' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
INFO:Benchmark for LLMs:2024-11-22, 17:55:59 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:56:25 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 17:56:25 Derived calculations done
INFO:Benchmark suite:2024-11-22, 17:56:25 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 30 : DONE
INFO:Benchmark suite:2024-11-22, 17:56:25 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 34
INFO:Benchmark for LLMs:2024-11-22, 17:56:25 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 17:56:25 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 17:57:17 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:57:54 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:58:37 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:59:20 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 17:59:57 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 18:00:41 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 18:01:24 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 18:01:54 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 18:01:54 Derived calculations done
INFO:Benchmark suite:2024-11-22, 18:01:54 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 34 : DONE
INFO:Benchmark suite:2024-11-22, 18:01:54 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 38
INFO:Benchmark for LLMs:2024-11-22, 18:01:54 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 18:01:54 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 18:02:46 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 18:03:23 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 18:04:00 300 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 18:04:50 400 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 18:05:27 500 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 18:06:05 600 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 18:06:55 700 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 18:07:28 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 18:07:28 Derived calculations done
INFO:Benchmark suite:2024-11-22, 18:07:28 Benchmarks for the generation speed, input length : 4096, output_length : 128, nb_requests : 38 : DONE
INFO:Benchmark suite:2024-11-22, 18:07:28 Benchmarks for the generation speed, input length : 4096, output_length : 128 : DONE
INFO:Benchmark suite:2024-11-22, 18:07:28 Beginning the benchmarks for the generation speed, input length : 4096, output_length : 1024
INFO:Benchmark suite:2024-11-22, 18:07:28 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 1
INFO:Benchmark for LLMs:2024-11-22, 18:07:28 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 18:07:28 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 18:19:02 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 18:19:02 Derived calculations done
INFO:Benchmark suite:2024-11-22, 18:19:02 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 1 : DONE
INFO:Benchmark suite:2024-11-22, 18:19:02 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 2
INFO:Benchmark for LLMs:2024-11-22, 18:19:02 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 18:19:02 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 18:25:47 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 18:25:47 Derived calculations done
INFO:Benchmark suite:2024-11-22, 18:25:47 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 2 : DONE
INFO:Benchmark suite:2024-11-22, 18:25:47 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 3
INFO:Benchmark for LLMs:2024-11-22, 18:25:47 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 18:25:47 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 18:31:30 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 18:31:30 Derived calculations done
INFO:Benchmark suite:2024-11-22, 18:31:30 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 3 : DONE
INFO:Benchmark suite:2024-11-22, 18:31:30 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 4
INFO:Benchmark for LLMs:2024-11-22, 18:31:30 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 18:31:30 Beginning the requests to the completions endpoint
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-5925173' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ServerDisconnectedError('Server disconnected')>
Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ServerDisconnectedError: Server disconnected
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-5925175' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ServerDisconnectedError('Server disconnected')>
Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ServerDisconnectedError: Server disconnected
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-5925179' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ServerDisconnectedError('Server disconnected')>
Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ServerDisconnectedError: Server disconnected
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-5925177' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ServerDisconnectedError('Server disconnected')>
Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ServerDisconnectedError: Server disconnected
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-5925171' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ServerDisconnectedError('Server disconnected')>
Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ServerDisconnectedError: Server disconnected
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-5925181' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ServerDisconnectedError('Server disconnected')>
Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ServerDisconnectedError: Server disconnected
INFO:Benchmark for LLMs:2024-11-22, 18:37:14 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 18:37:14 Derived calculations done
INFO:Benchmark suite:2024-11-22, 18:37:14 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 4 : DONE
INFO:Benchmark suite:2024-11-22, 18:37:14 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 6
INFO:Benchmark for LLMs:2024-11-22, 18:37:14 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 18:37:14 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 18:42:55 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 18:43:07 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 18:43:07 Derived calculations done
INFO:Benchmark suite:2024-11-22, 18:43:07 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 6 : DONE
INFO:Benchmark suite:2024-11-22, 18:43:07 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 8
INFO:Benchmark for LLMs:2024-11-22, 18:43:07 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 18:43:07 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 18:48:12 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 18:49:11 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 18:49:11 Derived calculations done
INFO:Benchmark suite:2024-11-22, 18:49:11 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 8 : DONE
INFO:Benchmark suite:2024-11-22, 18:49:11 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 10
INFO:Benchmark for LLMs:2024-11-22, 18:49:11 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 18:49:11 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 18:53:37 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 18:55:05 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 18:55:05 Derived calculations done
INFO:Benchmark suite:2024-11-22, 18:55:05 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 10 : DONE
INFO:Benchmark suite:2024-11-22, 18:55:05 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 14
INFO:Benchmark for LLMs:2024-11-22, 18:55:05 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 18:55:05 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 18:59:29 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 19:01:14 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 19:01:14 Derived calculations done
INFO:Benchmark suite:2024-11-22, 19:01:14 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 14 : DONE
INFO:Benchmark suite:2024-11-22, 19:01:14 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 18
INFO:Benchmark for LLMs:2024-11-22, 19:01:15 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 19:01:15 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 19:05:26 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 19:07:38 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 19:07:39 Derived calculations done
INFO:Benchmark suite:2024-11-22, 19:07:39 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 18 : DONE
INFO:Benchmark suite:2024-11-22, 19:07:39 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 22
INFO:Benchmark for LLMs:2024-11-22, 19:07:39 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 19:07:39 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 19:11:31 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 19:13:56 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 19:13:56 Derived calculations done
INFO:Benchmark suite:2024-11-22, 19:13:56 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 22 : DONE
INFO:Benchmark suite:2024-11-22, 19:13:56 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 26
INFO:Benchmark for LLMs:2024-11-22, 19:13:56 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 19:13:56 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 19:17:25 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 19:20:42 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 19:20:44 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 19:20:44 Derived calculations done
INFO:Benchmark suite:2024-11-22, 19:20:44 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 26 : DONE
INFO:Benchmark suite:2024-11-22, 19:20:44 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 30
INFO:Benchmark for LLMs:2024-11-22, 19:20:44 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 19:20:44 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 19:24:28 100 queries have been completed
ERROR:asyncio:Task exception was never retrieved
future: <Task finished name='Task-6424595' coro=<get_live_metrics() done, defined at /opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py:29> exception=ClientOSError(104, 'Connection reset by peer')>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/asyncio/selector_events.py", line 999, in _read_ready__data_received
    data = self._sock.recv(self.max_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/lib/python3.11/site-packages/benchmark_llm_serving/utils_metrics.py", line 41, in get_live_metrics
    async with session.get(url=metrics_url) as response:
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 1197, in __aenter__
    self._resp = await self._coro
                 ^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client.py", line 608, in _request
    await resp.start(conn)
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 976, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/aiohttp/streams.py", line 640, in read
    await self._waiter
aiohttp.client_exceptions.ClientOSError: [Errno 104] Connection reset by peer
INFO:Benchmark for LLMs:2024-11-22, 19:27:31 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 19:27:31 Derived calculations done
INFO:Benchmark suite:2024-11-22, 19:27:31 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 30 : DONE
INFO:Benchmark suite:2024-11-22, 19:27:31 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 34
INFO:Benchmark for LLMs:2024-11-22, 19:27:31 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 19:27:31 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 19:31:15 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 19:34:29 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 19:34:30 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 19:34:30 Derived calculations done
INFO:Benchmark suite:2024-11-22, 19:34:30 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 34 : DONE
INFO:Benchmark suite:2024-11-22, 19:34:30 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 38
INFO:Benchmark for LLMs:2024-11-22, 19:34:30 Loading the dataset
INFO:Benchmark for LLMs:2024-11-22, 19:34:31 Beginning the requests to the completions endpoint
INFO:Benchmark for LLMs:2024-11-22, 19:38:14 100 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 19:41:41 200 queries have been completed
INFO:Benchmark for LLMs:2024-11-22, 19:41:42 Requests to the completions endpoint done
INFO:Benchmark for LLMs:2024-11-22, 19:41:42 Derived calculations done
INFO:Benchmark suite:2024-11-22, 19:41:42 Benchmarks for the generation speed, input length : 4096, output_length : 1024, nb_requests : 38 : DONE
INFO:Benchmark suite:2024-11-22, 19:41:42 Benchmarks for the generation speed, input length : 4096, output_length : 1024 : DONE
INFO:Benchmark suite:2024-11-22, 19:41:42 Benchmarks for the generation speed : DONE
INFO:Benchmark suite:2024-11-22, 19:41:42 Drawing graphs
INFO:Making the graphs:2024-11-22, 19:41:42 Loading the results
INFO:Making the graphs:2024-11-22, 19:41:43 Making prompt ingestion graph
INFO:Making the graphs:2024-11-22, 19:41:43 Making speed generation graphs
INFO:Making the graphs:2024-11-22, 19:41:45 Making kv cache profile graphs
INFO:Making the graphs:2024-11-22, 19:41:48 Making total speed generation graph
INFO:Making the graphs:2024-11-22, 19:41:48 Graphs done
INFO:Benchmark suite:2024-11-22, 19:41:48 Drawing graphs : DONE
INFO:Benchmark suite:2024-11-22, 19:41:48 Making readme
INFO:Benchmark suite:2024-11-22, 19:41:48 Making readme : DONE
INFO:Benchmark suite:2024-11-22, 19:41:48 Zipping raw_results folder
INFO:Benchmark suite:2024-11-22, 19:41:49 Zipping raw_results folder : DONE
INFO:Benchmark suite:2024-11-22, 19:41:49 Everything : DONE
