{
    "model": "Phi-3-vision-128k-instruct",
    "step_live_metrics": 0.01,
    "max_queries": 1000,
    "request_rate": 0,
    "backend": "happy_vllm",
    "suite_id": "2024-09-17, 15:27:49",
    "model_name": "Phi-3-vision-128k-instruct",
    "happy_vllm_version": "1.1.9",
    "vllm_version": "0.6.1.post2",
    "host": "0.0.0.0",
    "port": 8501,
    "app_name": "happy_vllm",
    "api_endpoint_prefix": "/api_vllm/rs",
    "explicit_errors": false,
    "allow_credentials": false,
    "allowed_origins": [
        "*"
    ],
    "allowed_methods": [
        "*"
    ],
    "allowed_headers": [
        "*"
    ],
    "uvicorn_log_level": "info",
    "ssl_keyfile": null,
    "ssl_certfile": null,
    "ssl_ca_certs": null,
    "ssl_cert_reqs": 0,
    "root_path": null,
    "lora_modules": null,
    "chat_template": null,
    "response_role": "assistant",
    "with_launch_arguments": true,
    "max_log_len": null,
    "prompt_adapters": null,
    "return_tokens_as_token_ids": false,
    "disable_frontend_multiprocessing": true,
    "enable_auto_tool_choice": false,
    "tool_call_parser": null,
    "tokenizer": null,
    "skip_tokenizer_init": false,
    "revision": null,
    "code_revision": null,
    "tokenizer_revision": null,
    "tokenizer_mode": "auto",
    "trust_remote_code": true,
    "download_dir": null,
    "load_format": "auto",
    "config_format": "auto",
    "dtype": "auto",
    "kv_cache_dtype": "auto",
    "quantization_param_path": null,
    "max_model_len": 100000,
    "guided_decoding_backend": "outlines",
    "distributed_executor_backend": null,
    "worker_use_ray": false,
    "pipeline_parallel_size": 1,
    "tensor_parallel_size": 1,
    "max_parallel_loading_workers": null,
    "ray_workers_use_nsight": false,
    "block_size": 16,
    "enable_prefix_caching": false,
    "disable_sliding_window": false,
    "use_v2_block_manager": false,
    "num_lookahead_slots": 0,
    "seed": 0,
    "swap_space": 4.0,
    "cpu_offload_gb": 0.0,
    "gpu_memory_utilization": 0.9,
    "num_gpu_blocks_override": null,
    "max_num_batched_tokens": null,
    "max_num_seqs": 256,
    "max_logprobs": 20,
    "disable_log_stats": false,
    "quantization": null,
    "rope_scaling": null,
    "rope_theta": null,
    "enforce_eager": false,
    "max_context_len_to_capture": null,
    "max_seq_len_to_capture": 8192,
    "disable_custom_all_reduce": false,
    "tokenizer_pool_size": 0,
    "tokenizer_pool_type": "ray",
    "tokenizer_pool_extra_config": null,
    "limit_mm_per_prompt": null,
    "enable_lora": false,
    "max_loras": 1,
    "max_lora_rank": 16,
    "lora_extra_vocab_size": 256,
    "lora_dtype": "auto",
    "long_lora_scaling_factors": null,
    "max_cpu_loras": null,
    "fully_sharded_loras": false,
    "enable_prompt_adapter": false,
    "max_prompt_adapters": 1,
    "max_prompt_adapter_token": 0,
    "device": "auto",
    "num_scheduler_steps": 1,
    "scheduler_delay_factor": 0.0,
    "enable_chunked_prefill": null,
    "speculative_model": null,
    "speculative_model_quantization": null,
    "num_speculative_tokens": null,
    "speculative_draft_tensor_parallel_size": null,
    "speculative_max_model_len": null,
    "speculative_disable_by_batch_size": null,
    "ngram_prompt_lookup_max": null,
    "ngram_prompt_lookup_min": null,
    "spec_decoding_acceptance_method": "rejection_sampler",
    "typical_acceptance_sampler_posterior_threshold": null,
    "typical_acceptance_sampler_posterior_alpha": null,
    "disable_logprobs_during_spec_decoding": null,
    "model_loader_extra_config": null,
    "ignore_patterns": [],
    "preemption_mode": null,
    "served_model_name": null,
    "qlora_adapter_name_or_path": null,
    "otlp_traces_endpoint": null,
    "collect_detailed_traces": null,
    "disable_async_output_proc": false,
    "override_neuron_config": null,
    "disable_log_requests": false,
    "engine_use_ray": false,
    "gpu_name": "A100-80g"
}